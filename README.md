# Blood Vessel Segmentation Models Separating Thick and Thin Vessels in Retinal Images

Segmenting retinal fundus images Investigating the differences of a network trained on ground truth containing all vessels and the concatenation of network outputs trained on ground truth of thin vessels and a ground truth for thick vessels (vessel width > 3 pixels).

Preprocessing: Split_Vessels.py: The model will be trained on thick and thin vessels seperately. For this the ground truth of the data set should be split up. Thickness threshold: the minimum amound of pixels for which a vessel will be classified as thick. First the skeleton of the segmented vessels will be made. Also the smallest distance from the skelet to the background will be determined. This distance and the thickness threshold will be used to determine wheter the vessel should be classified as thick or thin. The draw Circles part de-skeletonize the skeletons of the vessels. Output: The images with thin and images with thick vessels segmented.

Data augmentation: Mutate_data.py: In this code, data is augmentated by mutating the original training set. There are 4 operations, which are randomly applied to the training images using random.randint(0,3). 1) Rotation: The image, mask and segmentations of the trainingset are fliped over the x-axis, the y-axis or both. The flip direction is randomly chosen again using random.randint(0,2); 2) Noise: A normal distributed noise is only applied to the actual image; 3) Contrast change: The pixel values of the image is multiplied with a random chosen integer between 0.5 and 1.5; 4) Blur Kernel: Gaussian blur with sigma 2 is applied to the image. Input parameters: images, masks, segmentations: the original of the training set. noise_strength: integer, is used as standard deviation in the noise operation. new_records: amount of generated training samples which will be added to the original. Output: The original and generated images, masks and segmentations.

Training: Unet_transfer.py: The used netwotk is the U-net, but it is adopted with transfer learning. Parameters from VGG11 trained on Imagenet data set are used to replace corresponding random initial values in U-Net. With its parameters fixed and fully-connected layers removed, VGG11 serves as an encoder in the U-Net network. Please always restart python console before running this file, otherwise the name of each layer would change. After transfering, the Unet cannot be fed for training immediatly. The transfered parameters should first be freezed and other layers should be trained first. Then transfered parameters could be freed and the whole network could be trained together. Learning rate for 'freezed-training' should be 1e-5.
